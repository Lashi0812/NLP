{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.strings import StringStore\n",
    "from spacy import attrs\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Good Morning, I want to reserve a ticket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(vocab=nlp.vocab)\n",
    "#? matcher need to initialized by the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEP\n",
      "ENT_ID\n",
      "ENT_IOB\n",
      "ENT_KB_ID\n",
      "ENT_TYPE\n",
      "Errors\n",
      "HEAD\n",
      "ID\n",
      "IDS\n",
      "IDX\n",
      "IOB_STRINGS\n",
      "IS_ALPHA\n",
      "IS_ASCII\n",
      "IS_BRACKET\n",
      "IS_CURRENCY\n",
      "IS_DIGIT\n",
      "IS_LEFT_PUNCT\n",
      "IS_LOWER\n",
      "IS_OOV_DEPRECATED\n",
      "IS_PUNCT\n",
      "IS_QUOTE\n",
      "IS_RIGHT_PUNCT\n",
      "IS_SPACE\n",
      "IS_STOP\n",
      "IS_TITLE\n",
      "IS_UPPER\n",
      "LANG\n",
      "LEMMA\n",
      "LENGTH\n",
      "LIKE_EMAIL\n",
      "LIKE_NUM\n",
      "LIKE_URL\n",
      "LOWER\n",
      "MORPH\n",
      "NAMES\n",
      "NORM\n",
      "ORTH\n",
      "POS\n",
      "PREFIX\n",
      "SENT_START\n",
      "SHAPE\n",
      "SPACY\n",
      "SUFFIX\n",
      "TAG\n",
      "intify_attr\n",
      "intify_attrs\n",
      "key\n",
      "value\n"
     ]
    }
   ],
   "source": [
    "for attr in dir(attrs):\n",
    "    if not (attr.startswith(\"FLAG\") or attr.startswith(\"__\")):\n",
    "        print(attr)\n",
    "\n",
    "#? these are the available token attribute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower and is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{attrs.LOWER:\"good\"},{attrs.LOWER:\"morning\"},{attrs.IS_PUNCT:True}]\n",
    "matcher.add(key=\"morningGreeting\",patterns=[pattern1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 Good Morning,\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(start,end,m_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern2 = [{attrs.LOWER:\"good\"},{attrs.LOWER:\"evening\"},{attrs.IS_PUNCT:True}]\n",
    "matcher.add(key=\"eveningGreeting\",patterns=[pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Good morning, I want to reserve a ticket. I will then say good evening!\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning,\n",
      "good evening!\n"
     ]
    }
   ],
   "source": [
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORTH\n",
    "\n",
    "it matches the text with same exact case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern3 = [{attrs.ORTH:\"i\"}]\n",
    "matcher.add(\"i\",patterns=[pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning,\n",
      "good evening!\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11099143382904271360: [[{66: 'good'}, {66: 'morning'}, {5: True}]],\n",
       " 13992137771284315935: [[{66: 'good'}, {66: 'evening'}, {5: True}]],\n",
       " 5097672513440128799: [[{65: 'i'}]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher._patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11099143382904271360: [[{66: 'good'}, {66: 'morning'}, {5: True}]],\n",
       " 13992137771284315935: [[{66: 'good'}, {66: 'evening'}, {5: True}]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher._patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern3 = [{attrs.ORTH:\"I\"}]\n",
    "matcher.add(\"I\",patterns=[pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning,\n",
      "I\n",
      "I\n",
      "good evening!\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern4 = [{attrs.LENGTH:4}]\n",
    "matcher.add(\"length of 4\",patterns=[pattern4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good\n",
      "Good morning,\n",
      "I\n",
      "want\n",
      "I\n",
      "will\n",
      "then\n",
      "good\n",
      "good evening!\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13992137771284315935"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11099143382904271360: [[{66: 'good'}, {66: 'morning'}, {5: True}]],\n",
       " 13992137771284315935: [[{66: 'good'}, {66: 'evening'}, {5: True}]],\n",
       " 4690420944186131903: [[{65: 'I'}]],\n",
       " 5913418915722860132: [[{71: 4}]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher._patterns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elephant\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"There is an elephant.\")\n",
    "pattern5 = [{attrs.IS_STOP:False}]\n",
    "matcher.add(\"remove stop words\",patterns=[pattern5])\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    if match_id == 729437288482027326:\n",
    "        m_span = doc[start:end]\n",
    "        print(m_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729437288482027326"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.strings[\"remove stop words\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove(\"remove stop words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "million\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"it cost me million.\")\n",
    "pattern6 =[{attrs.LIKE_NUM:True}]\n",
    "matcher.add(\"numbers\",patterns=[pattern6])\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    if match_id == nlp.vocab.strings[\"numbers\"]:\n",
    "        m_span = doc[start:end]\n",
    "        print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended syntax \n",
    "\n",
    "\"IN\" - member operator\n",
    "\"NOT_IN\"\n",
    "\"<=\" ,\">=\" ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Good morning, I want to reserve a ticket. I will then say good evening!\")\n",
    "\n",
    "#? we have used two pattern to match the two different but they have some common in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3248590692569088154: [[{66: 'good'}, {66: {'IN': ['morning', 'evening']}}]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern1 = [{attrs.LOWER:\"good\"},\n",
    "            {attrs.LOWER:{\"IN\":[\"morning\",\"evening\"]}}]\n",
    "matcher.add(\"greetings\",patterns=[pattern1])\n",
    "matcher._patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning\n",
      "good evening\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id ,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token whose length is greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I suffered from Trichotillomania when I was in college. The doctor prescribed me Psychosomatic medicine.\")\n",
    "pattern2 = [{attrs.LENGTH:{\">=\":10}}]\n",
    "matcher.add(\"greaterThan10\",patterns=[pattern2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trichotillomania\n",
      "prescribed\n",
      "Psychosomatic\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regex like operator\n",
    "\n",
    "1. \"?\" -- optional.\n",
    "2. \"+\" -- one or more time.\n",
    "3. \"*\" -- zero or multiple time.\n",
    "4. {} -- wildcard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ? optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Barack Obama visited France.\")\n",
    "doc2 = nlp(\"Barack Hussein Obama visited France.\")\n",
    "matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama\n",
      "Barack Hussein Obama\n"
     ]
    }
   ],
   "source": [
    "pattern = [{attrs.LOWER:\"barack\"},\n",
    "           {attrs.LOWER:\"hussein\",\"OP\":\"?\"},\n",
    "           {attrs.LOWER:\"obama\"}]\n",
    "matcher.add(\"optional\",patterns=[pattern])\n",
    "for doc in [doc1,doc2]:\n",
    "    matches = matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        m_span = doc[start:end]\n",
    "        print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### + once or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Hello hello hello, how are you?\")\n",
    "doc2 = nlp(\"Hello, how are you?\")\n",
    "doc3 = nlp(\"How are you?\")\n",
    "matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello,\n",
      "hello hello,\n",
      "Hello hello hello,\n",
      "Hello,\n"
     ]
    }
   ],
   "source": [
    "pattern = [{attrs.LOWER:\"hello\",\"OP\":\"+\"},\n",
    "           {attrs.IS_PUNCT:True}]\n",
    "matcher.add(\"once\",patterns=[pattern])\n",
    "for doc in [doc1,doc2,doc3]:\n",
    "    matches = matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        m_span = doc[start:end]\n",
    "        print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * zero or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Hello hello hello, how are you?\")\n",
    "doc2 = nlp(\"Hello, how are you?\")\n",
    "doc3 = nlp(\"How are you?\")\n",
    "matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello hello hello,\n",
      "hello hello,\n",
      "hello,\n",
      ",\n",
      "?\n",
      "Hello,\n",
      ",\n",
      "?\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "pattern = [{attrs.LOWER:\"hello\",\"OP\":\"*\"},\n",
    "           {attrs.IS_PUNCT:True}]\n",
    "matcher.add(\"more\",patterns=[pattern])\n",
    "for doc in [doc1,doc2,doc3]:\n",
    "    matches = matcher(doc)\n",
    "    for match_id,start,end in matches:\n",
    "        m_span = doc[start:end]\n",
    "        print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### {} wildcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"My name is Alice and his name was Elliot.\")\n",
    "matcher = Matcher(vocab=nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name is Alice\n",
      "name was Elliot\n"
     ]
    }
   ],
   "source": [
    "pattern = [{attrs.LOWER:\"name\"},\n",
    "           {attrs.LEMMA:\"be\"},\n",
    "           {} # match for the wild char\n",
    "           ]\n",
    "matcher.add(\"findName\",patterns=[pattern])\n",
    "matches = matcher(doc)\n",
    "for _,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went\n",
      "has\n",
      "been\n",
      "has\n",
      "told\n",
      "wants\n",
      "visit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I went to Italy; he has been there too. His mother  also has told me she wants to visit Rome.\")\n",
    "pattern = [{attrs.TAG:{\"REGEX\":\"^V\"}}]\n",
    "matcher = Matcher(vocab=nlp.vocab)\n",
    "matcher.add(\"verb\",patterns=[pattern])\n",
    "matches = matcher(doc)\n",
    "for _,start,end in matches:\n",
    "    m_span = doc[start:end]\n",
    "    print(m_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea56c0b954ae67294c7ca9bf9c057fc748d59d22faedcf3e8a57e0a70ba84c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
