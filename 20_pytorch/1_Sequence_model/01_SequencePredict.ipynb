{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from collections import (\n",
    "    OrderedDict,Counter\n",
    ")\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import default_collate\n",
    "## other\n",
    "from torchdata import datapipes as dp\n",
    "from torchtext import vocab\n",
    "from torchdata.dataloader2 import DataLoader2\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# manipulation\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# others\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # data\n",
    "    data_base_path = \"../../data/surnames/\",\n",
    "    dataset = [\"train\",\"test\",\"val\"],\n",
    "    \n",
    "    # vocab\n",
    "    mask_tkn = \"<MASK>\",\n",
    "    ukn_tkn = \"<UKN>\",\n",
    "    beg_tkn = \"<B>\",\n",
    "    end_tkn = \"<E>\",\n",
    "    \n",
    "    # model\n",
    "    embedding_size = 10,\n",
    "    rnn_hidden_state = 9,\n",
    "    model_base_path = \"../../models/seq_model/seq_pred\",\n",
    "    model_filename = \"model.pth\",\n",
    "    \n",
    "    # Training\n",
    "    num_epochs = 100,\n",
    "    batch_size = 2,\n",
    "    learning_rate = 1e-3,\n",
    "    seed = 1423,\n",
    "    \n",
    "    # runtime\n",
    "    cuda = torch.cuda.is_available(),\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "for k,v in args._get_kwargs():\n",
    "    if \"base\" in k:\n",
    "        Path(v).mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapipe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build pipe dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_dict(args=args):\n",
    "    pipe_dict = {}\n",
    "    for fname in args.dataset:\n",
    "        pipe_dict[fname] = dp.iter.FileOpener([args.data_base_path+f\"{fname}.csv\"]).parse_csv()\n",
    "    return pipe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': CSVParserIterDataPipe,\n",
       " 'test': CSVParserIterDataPipe,\n",
       " 'val': CSVParserIterDataPipe}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dict = build_pipe_dict()\n",
    "pipe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 7684, 'test': 1648, 'val': 1648}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:len(list(pipe)) for k,pipe in pipe_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['Woodford', 'English'],\n",
       " 'test': ['Kore', 'English'],\n",
       " 'val': ['Winship', 'English']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:next(iter(pipe)) for k,pipe in pipe_dict.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build vocab dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_dict(train_pipe,args=args):\n",
    "    name_counter = Counter()\n",
    "    nation_counter = Counter()\n",
    "    max_seq_length = -1\n",
    "    for name,nation in train_pipe:\n",
    "        max_seq_length = max(len(name),max_seq_length)\n",
    "        name_counter.update(name)\n",
    "        nation_counter.update([nation])\n",
    "        \n",
    "    sort_fn = lambda kf : (-kf[1],kf[0])\n",
    "    name_sort_tuples = sorted(name_counter.items(),key=sort_fn)\n",
    "    nation_sort_tuples = sorted(nation_counter.items(),key=sort_fn)\n",
    "    \n",
    "    name_vocab = vocab.vocab(ordered_dict=OrderedDict(name_sort_tuples),\n",
    "                             specials=[args.mask_tkn,\n",
    "                                       args.ukn_tkn,\n",
    "                                       args.beg_tkn,\n",
    "                                       args.end_tkn])\n",
    "    name_vocab.set_default_index(name_vocab[args.ukn_tkn])\n",
    "    name_vocab.max_seq_length = max_seq_length + 2\n",
    "    \n",
    "    nation_vocab = vocab.vocab(ordered_dict=OrderedDict(nation_sort_tuples))\n",
    "    freq = [count for _,count in nation_sort_tuples]\n",
    "    nation_vocab.class_weights = 1.0 / torch.tensor(freq)\n",
    "    \n",
    "    return {\"char\":name_vocab,\n",
    "            \"nation\":nation_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char': Vocab(), 'nation': Vocab()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = build_vocab_dict(pipe_dict[\"train\"])\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char': 83, 'nation': 18}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:len(vocab) for k,vocab in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"char\"].max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0005, 0.0006, 0.0009, 0.0018, 0.0024, 0.0025, 0.0034, 0.0055, 0.0060,\n",
       "        0.0063, 0.0065, 0.0078, 0.0092, 0.0119, 0.0189, 0.0192, 0.0250, 0.0263])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"nation\"].class_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(name,char_vocab,args=args):\n",
    "    indices = [char_vocab[args.beg_tkn]]\n",
    "    indices.extend(char_vocab.lookup_indices(list(name)))\n",
    "    indices.append(char_vocab[args.end_tkn])\n",
    "    \n",
    "    from_vector = np.full(shape=char_vocab.max_seq_length,\n",
    "                          fill_value=char_vocab[args.mask_tkn],\n",
    "                          dtype=np.int64)\n",
    "    from_indices = indices[:-1]\n",
    "    from_vector[:len(from_indices)] = from_indices\n",
    "    \n",
    "    to_vector = np.full(shape=char_vocab.max_seq_length,\n",
    "                        fill_value=char_vocab[args.mask_tkn],\n",
    "                        dtype=np.int64)\n",
    "    to_indices = indices[1:]\n",
    "    to_vector[:len(to_indices)] = to_indices\n",
    "    \n",
    "    return from_vector,to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 11,  4, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0], dtype=int64),\n",
       " array([11,  4, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(\"lak\",vocab_dict[\"char\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(vocab_dict,args,row):\n",
    "    from_vector , to_vector  = vectorize(row[0],char_vocab=vocab_dict[\"char\"],args=args)\n",
    "    nation_index = vocab_dict[\"nation\"][row[1]]\n",
    "    \n",
    "    return {\"x\":from_vector,\n",
    "            \"y\":to_vector,\n",
    "            \"class_index\":nation_index}\n",
    "    \n",
    "def collate_fn(args,batch):\n",
    "    return {k:v.to(args.device)\n",
    "            for k,v in default_collate(batch).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_dict(pipe_dict,vocab_dict,args=args):\n",
    "    dataset_dict = {}\n",
    "    fn = partial(create_dataset,vocab_dict,args)\n",
    "    for dataset,pipe in pipe_dict.items():\n",
    "        if dataset == \"train\":\n",
    "            pipe = pipe.shuffle()\n",
    "        \n",
    "        pipe = pipe.map(fn)\n",
    "        pipe = pipe.batch(args.batch_size,drop_last=True)\n",
    "        pipe = pipe.collate(partial(collate_fn,args))\n",
    "        dataset_dict[dataset] = pipe\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': CollatorIterDataPipe,\n",
       " 'test': CollatorIterDataPipe,\n",
       " 'val': CollatorIterDataPipe}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = build_dataset_dict(pipe_dict,vocab_dict)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3842, 'test': 824, 'val': 824}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:len(list(pipe)) for k,pipe in dataset_dict.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameGenerativeModel(nn.Module):\n",
    "    def __init__(self,char_embedding_size,char_vocab_size,\n",
    "                 rnn_hidden_size,batch_first=True,padding_idx = 0,\n",
    "                 dropout_rate = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.char_emb = nn.Embedding(embedding_dim=char_embedding_size,\n",
    "                                     num_embeddings=char_vocab_size,\n",
    "                                     padding_idx=padding_idx)\n",
    "        self.rnn = nn.GRU(input_size = char_embedding_size,\n",
    "                          hidden_size = rnn_hidden_size,\n",
    "                          batch_first = batch_first)\n",
    "        self.fc = nn.Linear(in_features=rnn_hidden_size,\n",
    "                            out_features=char_vocab_size)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "    def forward(self,input,apply_softmax=False):\n",
    "        # shape [batch,seq_length]\n",
    "        x_emb = self.char_emb(input)\n",
    "        # shape [batch,seq,emb]\n",
    "        y_out,_ = self.rnn(x_emb)\n",
    "        # shape [batch,seq,hidden]\n",
    "        batch_size,seq_size,feat_size = y_out.size()\n",
    "        \n",
    "        y_out = y_out.contiguous().view(batch_size*seq_size,feat_size)\n",
    "        \n",
    "        y_out = self.fc(F.dropout(y_out,p=self.dropout_rate))\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out,dim=1)\n",
    "        \n",
    "        new_feat_size = y_out.shape[-1]\n",
    "        y_out = y_out.view(batch_size,seq_size,new_feat_size)\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurnameGenerativeModel(char_embedding_size=args.embedding_size,\n",
    "                               char_vocab_size=len(vocab_dict[\"char\"]),\n",
    "                               rnn_hidden_size=args.rnn_hidden_state,\n",
    "                               padding_idx=vocab_dict[\"char\"][args.mask_tkn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = build_pipe_dict()\n",
    "vocab_dict = build_vocab_dict(pipe_dict[\"train\"])\n",
    "dataset_dict = build_dataset_dict(pipe_dict,vocab_dict,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 2, 23,  4, 19,  5, 21, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0],\n",
       "         [ 2, 36,  6,  8, 13,  5, 20,  6,  9, 17,  6,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0]]),\n",
       " 'y': tensor([[23,  4, 19,  5, 21, 12,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0],\n",
       "         [36,  6,  8, 13,  5, 20,  6,  9, 17,  6,  3,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0]]),\n",
       " 'class_index': tensor([2, 4])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(dataset_dict[\"train\"]))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"char\"].max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed = model.char_emb(sample[\"x\"])\n",
    "sample_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rnn,_ = model.rnn(sample_embed)\n",
    "sample_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 9])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size,seq_size,feat_size = sample_rnn.size()\n",
    "sample_out = sample_rnn.contiguous().view(batch_size*seq_size,feat_size)\n",
    "sample_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dict[\"char\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 83])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_fc = model.fc(sample_out)\n",
    "sample_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 19, 83])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y_pred = sample_fc.view(batch_size,seq_size,-1)\n",
    "sample_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1896, -0.2189,  0.0741,  ...,  0.2338, -0.0344, -0.2021],\n",
       "         [ 0.2890, -0.5058,  0.3368,  ...,  0.2131, -0.0575, -0.4025],\n",
       "         [ 0.2100, -0.3422,  0.2796,  ...,  0.1858, -0.2470, -0.3566],\n",
       "         ...,\n",
       "         [ 0.2238, -0.3094,  0.1804,  ...,  0.0646, -0.1630, -0.3456],\n",
       "         [ 0.2238, -0.3094,  0.1806,  ...,  0.0649, -0.1632, -0.3451],\n",
       "         [ 0.2237, -0.3093,  0.1807,  ...,  0.0650, -0.1634, -0.3448]],\n",
       "\n",
       "        [[ 0.1896, -0.2189,  0.0741,  ...,  0.2338, -0.0344, -0.2021],\n",
       "         [ 0.2557, -0.4169,  0.0987,  ..., -0.0110, -0.1196, -0.3164],\n",
       "         [ 0.1859, -0.2784,  0.1836,  ...,  0.0848, -0.2731, -0.2868],\n",
       "         ...,\n",
       "         [ 0.2282, -0.2930,  0.1882,  ...,  0.0735, -0.1640, -0.3412],\n",
       "         [ 0.2262, -0.2988,  0.1854,  ...,  0.0708, -0.1632, -0.3417],\n",
       "         [ 0.2250, -0.3025,  0.1837,  ...,  0.0688, -0.1630, -0.3423]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1896, -0.2189,  0.0741,  ...,  0.2338, -0.0344, -0.2021],\n",
       "        [ 0.2890, -0.5058,  0.3368,  ...,  0.2131, -0.0575, -0.4025],\n",
       "        [ 0.2100, -0.3422,  0.2796,  ...,  0.1858, -0.2470, -0.3566],\n",
       "        ...,\n",
       "        [ 0.2282, -0.2930,  0.1882,  ...,  0.0735, -0.1640, -0.3412],\n",
       "        [ 0.2262, -0.2988,  0.1854,  ...,  0.0708, -0.1632, -0.3417],\n",
       "        [ 0.2250, -0.3025,  0.1837,  ...,  0.0688, -0.1630, -0.3423]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y_pred.view(-1,sample_y_pred.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23,  4, 19,  5, 21, 12,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0],\n",
       "        [36,  6,  8, 13,  5, 20,  6,  9, 17,  6,  3,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"y\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_size(y_pred,y_true):\n",
    "    if len(y_pred.size()) == 3:\n",
    "        # shape [batch,seq,hidden]\n",
    "        y_pred = y_pred.contiguous().view(-1,y_pred.size(dim=2))\n",
    "        # shape [batch*seq,hidden]\n",
    "    if len(y_true.size()) == 2:\n",
    "        # shape [batch,seq]\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "        # shape [batch*seq]\n",
    "    return y_pred,y_true\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def sequence_loss(y_pred,y_true,mask_index):\n",
    "    y_pred , y_true = normalize_size(y_pred,y_true)\n",
    "    return F.cross_entropy(input=y_pred, # shape [batch*seq,hidden]\n",
    "                           target=y_true, # shape [batch*seq]\n",
    "                           ignore_index=mask_index # this remove value in the target and wont compute loss \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.rand(size=(2,7,9))\n",
    "y_true = torch.randint(low=0,high=7,size=(2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 0, 3, 4, 4, 3],\n",
       "        [6, 2, 6, 4, 1, 5, 6]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1802)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_loss(y_pred,y_true,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(y_pred,y_true,mask_indices):\n",
    "    y_pred ,y_true = normalize_size(y_pred,y_true)\n",
    "    \n",
    "    _,y_pred_indices =y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices,y_true).float()\n",
    "    valid_indices = torch.ne(y_true,mask_indices).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "    \n",
    "    return (n_correct / n_valid)  * 100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.384615384615385"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(y_pred,y_true,0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args=args):\n",
    "    return {\"stop_early\":False,\n",
    "            \"early_stopping_step\":0,\n",
    "            \"early_stopping_val\":1e5,\n",
    "            \"epoch_index\":0,\n",
    "            \"model_filepath\":args.model_base_path+args.model_filename,\n",
    "            \"train_loss\":[],\n",
    "            \"train_acc\":[],\n",
    "            \"val_loss\":[],\n",
    "            \"val_acc\":[],\n",
    "            \"test_loss\":-1,\n",
    "            \"test_acc\":-1}\n",
    "\n",
    "def update_train_state(train_state,model,args=args):\n",
    "    if train_state[\"epoch_index\"] == 0:\n",
    "        torch.save(model.state_dict(),train_state[\"model_filepath\"])\n",
    "        train_state[\"stop_early\"] = False\n",
    "    \n",
    "    elif train_state[\"epoch_index\"] >= 1:\n",
    "        loss_tm1 , loss_t = train_state[\"val_loss\"][-2:]\n",
    "        if loss_t >= train_state[\"early_stopping_val\"]:\n",
    "            train_state[\"early_stopping_step\"] +=1\n",
    "        else:\n",
    "            torch.save(model.state_dict(),train_state[\"model_filepath\"])\n",
    "            train_state[\"early_stopping_step\"] = 0\n",
    "            \n",
    "        train_state[\"stop_early\"] = train_state[\"early_stopping_step\"] >= args.early_stopping_criteria\n",
    "    \n",
    "    return train_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = build_pipe_dict()\n",
    "vocab_dict = build_vocab_dict(pipe_dict[\"train\"])\n",
    "dataset_dict = build_dataset_dict(pipe_dict,vocab_dict,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SurnameGenerativeModel(char_embedding_size=args.embedding_size,\n",
    "                               char_vocab_size=len(vocab_dict[\"char\"]),\n",
    "                               rnn_hidden_size=args.rnn_hidden_state)\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                       lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode=\"min\",factor=0.5,\n",
    "                                                 patience=1)\n",
    "train_state = make_train_state(args)\n",
    "mask_index = vocab_dict[\"char\"][args.mask_tkn]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:35<59:15, 35.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\DataspellProjects\\NLP\\20_pytorch\\1_Sequence_model\\01_SequencePredict.ipynb Cell 51\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y126sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     acc_t \u001b[39m=\u001b[39m compute_acc(logits,batch_dict[\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m],mask_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y126sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     running_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (acc_t \u001b[39m-\u001b[39m running_acc) \u001b[39m/\u001b[39m (batch_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y126sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y126sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y126sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m train_state[\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(running_loss)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(args.num_epochs)):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    \n",
    "    # get the data\n",
    "    batch_generator = DataLoader2(datapipe=dataset_dict[\"train\"])\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        model.zero_grad()\n",
    "        logits = model(batch_dict[\"x\"])\n",
    "        \n",
    "        # loss\n",
    "        loss = sequence_loss(logits,batch_dict[\"y\"],mask_index)\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) /(batch_idx+1)\n",
    "        \n",
    "        # acc\n",
    "        acc_t = compute_acc(logits,batch_dict[\"y\"],mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx+1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_state[\"train_loss\"].append(running_loss)\n",
    "    train_state[\"train_acc\"].append(running_acc)\n",
    "    \n",
    "    # iterate over the val \n",
    "    batch_generator = DataLoader2(dataset_dict[\"val\"])\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        with torch.inference_mode():\n",
    "            logits = model(batch_dict[\"x\"])\n",
    "            \n",
    "            # loss\n",
    "            loss = sequence_loss(logits,batch_dict[\"y\"],mask_index)\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) /(batch_idx+1)\n",
    "            \n",
    "            # acc\n",
    "            acc_t = compute_acc(logits,batch_dict[\"y\"],mask_index)\n",
    "            running_acc += (acc_t - running_acc) / (batch_idx+1)   \n",
    "            \n",
    "    train_state[\"val_loss\"].append(running_loss)         \n",
    "    train_state[\"val_acc\"].append(running_acc)\n",
    "    \n",
    "    scheduler.step(train_state[\"val_loss\"][-1])\n",
    "    \n",
    "    if train_state[\"stop_early\"]:\n",
    "        break          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_state[\"train_loss\"],label=\"train_loss\")\n",
    "plt.plot(train_state[\"train_acc\"],label=\"train_acc\")\n",
    "plt.plot(train_state[\"val_loss\"],label=\"val_loss\")\n",
    "plt.plot(train_state[\"val_acc\"],label=\"val_acc\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\DataspellProjects\\NLP\\20_pytorch\\1_Sequence_model\\01_SequencePredict.ipynb Cell 52\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y131sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         acc_t \u001b[39m=\u001b[39m compute_acc(logits,batch_dict[\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m],mask_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y131sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         running_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (acc_t \u001b[39m-\u001b[39m running_acc) \u001b[39m/\u001b[39m (batch_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)   \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y131sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train_state[\u001b[39m\"\u001b[39;49m\u001b[39mtest_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mappend(running_loss)         \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/1_Sequence_model/01_SequencePredict.ipynb#Y131sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m train_state[\u001b[39m\"\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(running_acc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "batch_generator = DataLoader2(dataset_dict[\"test\"])\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "model.eval()\n",
    "\n",
    "for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "    with torch.inference_mode():\n",
    "        logits = model(batch_dict[\"x\"])\n",
    "        \n",
    "        # loss\n",
    "        loss = sequence_loss(logits,batch_dict[\"y\"],mask_index)\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) /(batch_idx+1)\n",
    "        \n",
    "        # acc\n",
    "        acc_t = compute_acc(logits,batch_dict[\"y\"],mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx+1)   \n",
    "        \n",
    "train_state[\"test_loss\"] = running_loss\n",
    "train_state[\"test_acc\"] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model,char_vocab,num_samples,sample_size=20,args=args):\n",
    "    # creating the begin index for all samples\n",
    "    begin_seq_index = [char_vocab[args.beg_tkn]\n",
    "                       for _ in range(num_samples)]\n",
    "    # converting and add dim\n",
    "    begin_seq_index = torch.tensor(begin_seq_index,dtype=torch.int64).unsqueeze(dim=1)\n",
    "    \n",
    "    indices = [begin_seq_index]\n",
    "    h_t = None\n",
    "    \n",
    "    for time_step in range(sample_size):\n",
    "        x_t = indices[time_step]\n",
    "        print(x_t.shape)\n",
    "        # shape [num_sample,1]\n",
    "        x_emd_t = model.char_emb(x_t)\n",
    "        print(x_emd_t.shape)\n",
    "        # shape [num_sample,1,emb]\n",
    "        rnn_t,h_t = model.rnn(x_emd_t,h_t)\n",
    "        print(rnn_t.shape)\n",
    "        print(h_t.shape)\n",
    "        # shape rnn_t [num_samples,1,hidden]\n",
    "        # shape h_t [1,hidden]\n",
    "        pred_vector = model.fc(\n",
    "            rnn_t.squeeze(dim=1)  # shape [num_sample,hidden]\n",
    "            )\n",
    "        print(pred_vector.shape)\n",
    "        # shape [num_sample,char_vocab_size]\n",
    "        prob_vector = F.softmax(pred_vector,dim=1)\n",
    "        # shape [num_sample,char_vocab_size]\n",
    "        indices.append(torch.multinomial(prob_vector,num_samples=1))\n",
    "    indices = torch.stack(indices)\n",
    "    print(indices.shape)\n",
    "    indices = indices.squeeze().permute(1,0)\n",
    "    return indices     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_samples(sampled_indices,char_vocab,args=args):\n",
    "    decoded_surnames = []\n",
    "    \n",
    "    for sample_index in range(sampled_indices.shape[0]):\n",
    "        surname = \"\"\n",
    "        for time_step in range(sampled_indices.shape[1]):\n",
    "            sample_item = sampled_indices[sample_index,time_step].item()\n",
    "            if sample_item == char_vocab[args.beg_tkn]:\n",
    "                continue\n",
    "            elif sample_item == char_vocab[args.end_tkn]:\n",
    "                break\n",
    "            else:\n",
    "                surname += char_vocab.get_itos()[sample_index]\n",
    "        decoded_surnames.append(surname)\n",
    "    return decoded_surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1, 10])\n",
      "torch.Size([10, 1, 9])\n",
      "torch.Size([1, 10, 9])\n",
      "torch.Size([10, 83])\n",
      "torch.Size([21, 10, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<MASK><MASK><MASK><MASK><MASK>',\n",
       " '<UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN><UKN>',\n",
       " '<B>',\n",
       " '<E><E><E><E>',\n",
       " 'aaaaa',\n",
       " 'eee',\n",
       " 'oooooo',\n",
       " 'ii',\n",
       " 'nnnnnnn',\n",
       " 'rrrrrrr']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_names = 10\n",
    "model = model.cpu()\n",
    "sampled_surnames = decode_samples(sample_from_model(model,vocab_dict[\"char\"],num_samples=num_names),\n",
    "                                  char_vocab=vocab_dict[\"char\"])\n",
    "sampled_surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
