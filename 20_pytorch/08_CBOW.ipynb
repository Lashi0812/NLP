{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "## data\n",
    "from torchdata import datapipes as dp\n",
    "## test\n",
    "from torchtext import vocab\n",
    "\n",
    "# manipulation\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # data\n",
    "    data_base_path = \"../data/cbow/\",\n",
    "    datasets = [\"train\",\"val\",\"test\"],\n",
    "    delimiter = \"#\",\n",
    "    \n",
    "    # vocab\n",
    "    mask_tkn = \"<MASK>\",\n",
    "    unk_tkn = \"<UKN>\",\n",
    "    window_size = 2,\n",
    "    \n",
    "    # model\n",
    "    \n",
    "    # training\n",
    "    batches = 32,\n",
    "    \n",
    "    # running options\n",
    "    cuda = torch.cuda.is_available(),\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener_dp = dp.iter.FileOpener([args.data_base_path+\"train.csv\"])\n",
    "parser_dp = opener_dp.parse_csv(delimiter=args.delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tuples(row):\n",
    "    return (row[0].split(\" \"),[row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_parsed_dict(args):\n",
    "    csv_pipe_dict = {}\n",
    "    for fname in args.datasets:\n",
    "        csv_pipe_dict[fname] = dp.iter\\\n",
    "            .FileOpener([args.data_base_path+f\"{fname}.csv\"])\\\n",
    "            .parse_csv(delimiter=args.delimiter)\\\n",
    "            .map(convert_to_tuples)\n",
    "    return csv_pipe_dict            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_parse_dict = open_parsed_dict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['start', 'of', 'project', 'gutenberg'], ['the'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(csv_parse_dict[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_context_target_fn(row):\n",
    "    return row[0]+row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start', 'of', 'project', 'gutenberg', 'the']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(csv_parse_dict[\"train\"].map(join_context_target_fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(train_pipe,args=args):\n",
    "    combined_dp = train_pipe.map(join_context_target_fn)\n",
    "    cbow_vocab = vocab.build_vocab_from_iterator(combined_dp,\n",
    "                                                 specials=[args.unk_tkn,args.mask_tkn])\n",
    "    cbow_vocab.set_default_index(cbow_vocab[args.unk_tkn])\n",
    "    return cbow_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_vocab = build_vocab(csv_parse_dict[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14053, 5, 5328, 5006]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_vocab.lookup_indices(['start', 'of', 'project', 'gutenberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_vocab.lookup_indices(['the'])[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(context,vocab,args):\n",
    "    indices = vocab.lookup_indices(context)\n",
    "    vector = np.zeros(args.window_size*2,dtype=np.float32)\n",
    "    vector[:len(indices)] = indices\n",
    "    vector[len(indices):] = vocab[args.mask_tkn]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_dict(vocab,args,row):\n",
    "    context_vector = vectorize(row[0],vocab=vocab,args=args)\n",
    "    target_index = vocab.lookup_indices(row[1])[-1]\n",
    "    return {\"x\":context_vector,\n",
    "            \"y\":target_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_dict(csv_parse_dict,vocab,args=args):\n",
    "    dataset_dict = {}\n",
    "    fn = partial(create_dataset_dict,vocab,args)\n",
    "    for dataset_name,csv_parse_pipe in csv_parse_dict.items():\n",
    "        if dataset_name == \"train\":\n",
    "            csv_parse_pipe = csv_parse_pipe.shuffle()\n",
    "        \n",
    "        dataset_dict[dataset_name] = csv_parse_pipe.map(fn).batch(args.batches)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = build_dataset_dict(csv_parse_dict,cbow_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': BatcherIterDataPipe,\n",
       " 'val': BatcherIterDataPipe,\n",
       " 'test': BatcherIterDataPipe}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(args,x):\n",
    "    return {k:v.to(args.device)\n",
    "            for x_ in default_collate(x)\n",
    "            for k,v in x_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset,args,shuffle):\n",
    "    dataloader = DataLoader(dataset=dataset,batch_size=args.batches,\n",
    "                            shuffle=shuffle,drop_last=True,\n",
    "                            collate_fn=partial(collate_fn,args),\n",
    "                            worker_init_fn=worker_init_fn)\n",
    "    for batch in dataloader:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
