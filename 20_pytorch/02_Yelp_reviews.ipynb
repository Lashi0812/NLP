{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "import string\n",
    "import json\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "from torchmetrics import Accuracy\n",
    "# utilities\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary \n",
    "\n",
    "1. Create the dictionary two dictionary that have bijection.\n",
    "    1. token to idx\n",
    "    2. idx to token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self,token_to_idx=None,add_unk=True,unk_token=\"<UNK>\") -> None:\n",
    "        \n",
    "        # creating the one dict for token to idx\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        \n",
    "        # another dict for idx to token\n",
    "        self._idx_to_token = {idx:token \n",
    "                              for token,idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "            \n",
    "    def add_token(self,token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        return index\n",
    "    \n",
    "    def add_tokens(self,tokens):\n",
    "        return [self.add_token(token) \n",
    "                for token in tokens]\n",
    "        \n",
    "    def lookup_token(self,token):\n",
    "        \"\"\"\n",
    "        Return the index of the token\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token,self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "        \n",
    "    def lookup_index(self,index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(f\"the index {index} is not in the Vocabulary.\")\n",
    "        return self._idx_to_token(index)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"<Vocabulary(size={len(self)})>\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)     \n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls,contents):\n",
    "        return cls(**contents)  \n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {\"token_to_idx\":self._token_to_idx,\n",
    "                \"add_unk\":self._add_unk,\n",
    "                \"unk_token\":self._unk_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    def __init__(self,review_vocab,rating_vocab) -> None:\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "    \n",
    "    def vectorize(self,review):\n",
    "        one_hot = np.zeros(shape=len(self.review_vocab),dtype=np.float32)\n",
    "        \n",
    "        for token in review:\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "        \n",
    "        return one_hot\n",
    "    \n",
    "    @classmethod \n",
    "    def from_dataframe(cls,review_df,cutoff=25):\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        \n",
    "        #? creating the rating vocab\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "        \n",
    "        #? word the word in whole rating dataframe\n",
    "        review_vocab.word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    review_vocab.word_counts[word] += 1\n",
    "        \n",
    "        #? creating the token greater than 25\n",
    "        for word,count in sorted(review_vocab.word_counts.items(), key=lambda x: (-x[1], x[0])):\n",
    "            if count >= cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "                \n",
    "        return cls(review_vocab,rating_vocab)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls,contents):\n",
    "        review_vocab = Vocabulary.from_serializable(contents[\"review_vocab\"])\n",
    "        rating_vocab = Vocabulary.from_serializable(contents[\"rating_vocab\"])\n",
    "        \n",
    "        return cls(review_vocab=review_vocab,rating_vocab=rating_vocab)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {\"review_vocab\":self.review_vocab.to_serializable(),\n",
    "                \"rating_vocab\":self.rating_vocab.to_serializable()}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,review_df,vectorizer) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.review_df = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df = self.review_df[self.review_df.split == \"train\"]\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.review_df[self.review_df.split == \"val\"]\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.review_df[self.review_df.split == \"test\"]\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self.lookup_dict = {\"train\":(self.train_df,self.train_size),\n",
    "                            \"val\":(self.val_df,self.val_size),\n",
    "                            \"test\":(self.test_df,self.test_size)}\n",
    "        \n",
    "        self.set_split(\"train\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        review_vector = self._vectorizer.vectorize(row.review)\n",
    "        rating_vector = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "        \n",
    "        return {\"x_data\":review_vector,\n",
    "                \"y_data\":rating_vector} \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls,review_csv):\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        train_review_df = review_df[review_df.split == \"train\"]\n",
    "        return cls(review_df,Vectorizer.from_dataframe(train_review_df))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls,review_csv,vectorizer_filepath):\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(review_df,vectorizer)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return Vectorizer.from_serializable(json.loads(fp))\n",
    "        \n",
    "    def save_vectorizer(self,vectorizer_filepath):\n",
    "        with open(vectorizer_filepath,\"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(json.load(fp)))\n",
    "            \n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self,split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df,self._target_size = self.lookup_dict[split]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def get_num_batches(self,batch_size):\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset,batch_size,shuffle=True,\n",
    "                     drop_last=True,device=\"cpu\"):\n",
    "    dataloader = DataLoader(dataset=dataset,batch_size=batch_size,\n",
    "                            drop_last=drop_last,shuffle=shuffle,\n",
    "                            worker_init_fn=worker_init_fn,\n",
    "                            )\n",
    "    \n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name in data_dict.keys():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = ReviewDataset.load_dataset_and_make_vectorizer(\"../data/reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([1., 0., 0., ..., 0., 0., 0.], dtype=float32), 'y_data': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = next(sample)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.get_vectorizer().review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_vectorizer().review_vocab.lookup_token(\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_vectorizer().review_vocab.lookup_token(\"biological\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_vectorizer().review_vocab.word_counts[\"biological\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21439"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_vectorizer().review_vocab.word_counts[\"place\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata import datapipes as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_open = dp.iter.FileOpener([\"../data/reviews_with_splits_lite.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_csv = file_open.parse_csv(skip_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(parse_csv,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('negative',),\n",
       " ('terrible place to work for i just heard a story of them find a girl over her biological father coming in there who she hadn t seen in years she said hi to him which upset his wife and they left she finished the rest of her day working fine the next day when she went into work they fired over that situation . i for one and boycotting texas roadhouse because any place that could be that cruel to their staff does not deserve my business . . . yelp wants me to give them a star but i don t believe they deserve it',),\n",
       " ('train',)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(select,row):\n",
    "    return row[2] == select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter  = parse_csv.filter(partial(filter_fn,\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('negative',),\n",
       " ('terrible place to work for i just heard a story of them find a girl over her biological father coming in there who she hadn t seen in years she said hi to him which upset his wife and they left she finished the rest of her day working fine the next day when she went into work they fired over that situation . i for one and boycotting texas roadhouse because any place that could be that cruel to their staff does not deserve my business . . . yelp wants me to give them a star but i don t believe they deserve it',),\n",
       " ('train',)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(train_filter,batch_size=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(row):\n",
    "    return row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = train_filter.map(get_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrible place to work for i just heard a story of them find a girl over her biological father coming in there who she hadn t seen in years she said hi to him which upset his wife and they left she finished the rest of her day working fine the next day when she went into work they fired over that situation . i for one and boycotting texas roadhouse because any place that could be that cruel to their staff does not deserve my business . . . yelp wants me to give them a star but i don t believe they deserve it']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(DataLoader(train_review,batch_size=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_token(review):\n",
    "    # print(\"getting token\",review,type(review))\n",
    "    return [token \n",
    "            for token in review.split(\" \")\n",
    "            if token not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token = train_review.map(get_review_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vocab = torchtext.vocab.build_vocab_from_iterator(train_token,min_freq=25,specials=[\"<unk>\"])\n",
    "review_vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab[\"sgg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab[\"story\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab[\"place\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab.lookup_token(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[993]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab.lookup_indices([\"story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rating(row):\n",
    "    return [row[0]]\n",
    "train_rating = train_filter.map(get_rating)\n",
    "next(iter(train_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_vocab = torchtext.vocab.build_vocab_from_iterator(train_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method lookup_indices in module torchtext.vocab.vocab:\n",
      "\n",
      "lookup_indices(tokens: List[str]) -> List[int] method of torchtext.vocab.vocab.Vocab instance\n",
      "    Args:\n",
      "        tokens: the tokens used to lookup their corresponding `indices`.\n",
      "    \n",
      "    Returns:\n",
      "        The 'indices` associated with `tokens`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(review_vocab.lookup_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab.lookup_indices([\"biological\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7497"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(len(review_vocab))[review_vocab.lookup_indices(next(iter(train_token)))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(review_vocab,rating_vocab,row):\n",
    "    review_vector = np.zeros(len(review_vocab))\n",
    "    review_vector[review_vocab.lookup_indices((get_review_token(row[1])))] = 1\n",
    "    \n",
    "    rating_vector = rating_vocab.lookup_indices([row[0]])[-1]\n",
    "    \n",
    "    return {\"x_data\":review_vector,\n",
    "            \"y_data\":rating_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dataset = train_filter.map(partial(create_dataset,review_vocab,rating_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_iter = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_vocab.lookup_indices([\"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(sample_iter[\"x_data\"] == row[\"x_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'terrible place to work for i just heard a story of them find a girl over her biological father coming in there who she hadn t seen in years she said hi to him which upset his wife and they left she finished the rest of her day working fine the next day when she went into work they fired over that situation . i for one and boycotting texas roadhouse because any place that could be that cruel to their staff does not deserve my business . . . yelp wants me to give them a star but i don t believe they deserve it',\n",
       " 'train']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(parse_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(split,row):\n",
    "    return row[2] == split\n",
    "\n",
    "def review_token_fn(row):\n",
    "    return [token\n",
    "            for token in row[1].split(\" \")\n",
    "            if token not in string.punctuation]\n",
    "\n",
    "def rating_token_fn(row):\n",
    "    return [row[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spilt(csv,split=\"train\"):\n",
    "    stream = dp.iter.FileOpener([csv])\n",
    "    row = stream.parse_csv(skip_lines=1)\n",
    "    return row.filter(partial(filter_fn,split))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(csv,unk_tkn=\"<unk>\"):\n",
    "    split = get_spilt(csv,\"train\")\n",
    "    \n",
    "    review_token = split.map(review_token_fn)    \n",
    "    review_vocab = torchtext.vocab.build_vocab_from_iterator(review_token,\n",
    "                                                             specials=[unk_tkn],min_freq=25)\n",
    "    review_vocab.set_default_index(review_vocab[unk_tkn])\n",
    "\n",
    "    rating_token = split.map(rating_token_fn)\n",
    "    rating_vocab = torchtext.vocab.build_vocab_from_iterator(rating_token)\n",
    "    \n",
    "    return review_vocab ,rating_vocab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vocab ,rating_vocab  = create_vocab(\"../data/reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(review_vocab,rating_vocab,row):\n",
    "    review_vector = np.zeros(len(review_vocab))\n",
    "    review_vector[review_vocab.lookup_indices((get_review_token(row[1])))] = 1\n",
    "    \n",
    "    rating_vector = rating_vocab.lookup_indices([row[0]])[-1]\n",
    "    \n",
    "    return {\"x_data\":review_vector,\n",
    "            \"y_data\":rating_vector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(csv,split,review_vocab,rating_vocab):\n",
    "    split_iter = get_spilt(csv,split)\n",
    "    if split == \"train\":\n",
    "        split_iter = split_iter.shuffle()\n",
    "    return split_iter.map(partial(create_dataset,review_vocab,rating_vocab))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"../data/reviews_with_splits_lite.csv\"\n",
    "train_dataset = build_dataset(CSV_PATH,\"train\",review_vocab,rating_vocab)\n",
    "val_dataset = build_dataset(CSV_PATH,\"val\",review_vocab,rating_vocab)\n",
    "test_dataset = build_dataset(CSV_PATH,\"test\",review_vocab,rating_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.datapipes.iter.callable.MapperIterDataPipe"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self,num_feature) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_feature,\n",
    "                             out_features=1)\n",
    "        \n",
    "    def forward(self,input,apply_sigmoid=False):\n",
    "        y_out = self.fc1(input).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            y_out = F.sigmoid(y_out)\n",
    "        return y_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting\n",
    "Hyperparameter and program option are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed,cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expand file paths: \n",
      "..\\models\\yelp\\model.pth\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "\n",
    "args = Namespace(\n",
    "    # data and path information\n",
    "    frequency_cutoff = 25,\n",
    "    model_state_file = \"model.pth\",\n",
    "    review_csv = \"../data/reviews_with_splits_lite.csv\",\n",
    "    save_dir = \"../models/yelp/\",\n",
    "    # Model hyperparameters\n",
    "    # Training Hyperparameters\n",
    "    batch_size = 128,\n",
    "    early_stopping_criteria = 5,\n",
    "    learning_rate = 0.001,\n",
    "    num_epochs = 100,\n",
    "    seed = 42,\n",
    "    # Runtime options\n",
    "    cuda=True,\n",
    "    expand_filepaths_to_save_dir = True,\n",
    "    reload_from_file = False\n",
    ")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    if not Path(args.save_dir).exists():\n",
    "        Path(args.save_dir).mkdir(parents=True,exist_ok=True)\n",
    "    args.model_state_file = str(Path(args.save_dir)/args.model_state_file)\n",
    "    \n",
    "    print(\"Expand file paths: \")\n",
    "    print(f\"{args.model_state_file}\")\n",
    "    \n",
    "args.cuda = torch.cuda.is_available()\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "set_seed_everywhere(args.seed,args.cuda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {\"stop_early\":False,\n",
    "            \"early_stopping_step\":0,\n",
    "            \"early_stopping_best_val\":1e8,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "            \"epoch_index\":0,\n",
    "            \"train_loss\":[],\n",
    "            \"train_acc\":[],\n",
    "            \"val_loss\":[],\n",
    "            \"val_acc\":[],\n",
    "            \"test_loss\":[],\n",
    "            \"test_acc\":[],\n",
    "            \"model_filename\":args.model_state_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_state(args,model,train_state):\n",
    "    \n",
    "    # save one model at least\n",
    "    if train_state[\"epoch_index\"] == 0:\n",
    "        torch.save(model.state_dict(),train_state[\"model_filename\"])\n",
    "        train_state[\"stop_early\"] = False\n",
    "        \n",
    "    # save the model if performed\n",
    "    elif train_state[\"epoch_index\"] >= 0:\n",
    "        loss_tm1 , loss_t = train_state[\"train_loss\"][-2:]\n",
    "        \n",
    "        # if model get worsen\n",
    "        if loss_t >= train_state[\"early_stopping_best_val\"]:\n",
    "            # update the early stopping step\n",
    "            train_state[\"early_stopping_step\"] += 1\n",
    "        \n",
    "        # loss decreased that is model is learning\n",
    "        else:\n",
    "            # save the model\n",
    "            if loss_t < train_state[\"early_stopping_best_val\"]:\n",
    "                torch.save(model.state_dict(),train_state[\"model_filename\"])\n",
    "                \n",
    "            # reset early stopping step\n",
    "            train_state[\"early_stopping_step\"] = 0\n",
    "        \n",
    "        #stop early\n",
    "        train_state[\"stop_early\"] = train_state[\"early_stopping_step\"] >= args.early_stopping_criteria\n",
    "    \n",
    "    return train_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ReviewClassifier(num_feature=len(review_vocab)).to(args.device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "acc_fn = Accuracy(task=\"binary\",num_classes=2)\n",
    "optimizer = optim.Adam(params=classifier.parameters(),\n",
    "                       lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode=\"min\",\n",
    "                                                 factor=0.5,\n",
    "                                                 patience=1)\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\graph_settings.py:74: UserWarning: `shuffle=True` was set, but the datapipe does not contain a `Shuffler`. Adding one at the end. Be aware that the default buffer size might not be sufficient for your task.\n",
      "  warnings.warn(\n",
      "  5%|▌         | 5/100 [02:00<38:14, 24.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\DataspellProjects\\NLP\\20_pytorch\\02_Yelp_reviews.ipynb Cell 70\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m running_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m classifier\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx,batch_dict \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch_generator):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# zero grad\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# forward pass\u001b[39;00m\n",
      "\u001b[1;32md:\\DataspellProjects\\NLP\\20_pytorch\\02_Yelp_reviews.ipynb Cell 70\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_batches\u001b[39m(dataset,batch_size,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                      drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mdataset,batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                             drop_last\u001b[39m=\u001b[39mdrop_last,shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             worker_init_fn\u001b[39m=\u001b[39mworker_init_fn)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data_dict \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         out_data_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m data_dict\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:34\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[0;32m     33\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[0;32m     35\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:185\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m    184\u001b[0m             _check_iterator_valid(datapipe, iterator_id)\n\u001b[1;32m--> 185\u001b[0m             response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\datapipe.py:351\u001b[0m, in \u001b[0;36m_IterDataPipeSerializationWrapper.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 351\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datapipe\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:185\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[39melse\u001b[39;00m:  \u001b[39m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[0;32m    184\u001b[0m             _check_iterator_valid(datapipe, iterator_id)\n\u001b[1;32m--> 185\u001b[0m             response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(request)\n\u001b[0;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:123\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[1;32m--> 123\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:88\u001b[0m, in \u001b[0;36mMapperIterDataPipe._apply_fn\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply_fn\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_col \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_col \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(data)\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_col \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(data)\n",
      "\u001b[1;32md:\\DataspellProjects\\NLP\\20_pytorch\\02_Yelp_reviews.ipynb Cell 70\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m review_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(review_vocab))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m review_vector[review_vocab\u001b[39m.\u001b[39mlookup_indices((get_review_token(row[\u001b[39m1\u001b[39m])))] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rating_vector \u001b[39m=\u001b[39m rating_vocab\u001b[39m.\u001b[39;49mlookup_indices([row[\u001b[39m0\u001b[39;49m]])[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mx_data\u001b[39m\u001b[39m\"\u001b[39m:review_vector,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DataspellProjects/NLP/20_pytorch/02_Yelp_reviews.ipynb#Y126sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_data\u001b[39m\u001b[39m\"\u001b[39m:rating_vector}\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torchtext\\vocab\\vocab.py:133\u001b[0m, in \u001b[0;36mVocab.lookup_indices\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m        indices: The `indices` used to lookup their corresponding`tokens`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m        RuntimeError: If an index within `indices` is not int range [0, itos.size()).\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mlookup_tokens(indices)\n\u001b[1;32m--> 133\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlookup_indices\u001b[39m(\u001b[39mself\u001b[39m, tokens: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[0;32m    135\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m        tokens: the tokens used to lookup their corresponding `indices`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m        The 'indices` associated with `tokens`.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mlookup_indices(tokens)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(args.num_epochs)):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    \n",
    "    batch_generator = generate_batches(dataset=train_dataset,batch_size=args.batch_size,\n",
    "                                       device=args.device)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    classifier.train()\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = classifier(batch_dict[\"x_data\"].float())\n",
    "        \n",
    "        # compute the loss\n",
    "        loss = loss_fn(y_pred,batch_dict[\"y_data\"].float())\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_idx+1)\n",
    "        \n",
    "        # back loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute the accuracy\n",
    "        acc_t = acc_fn(y_pred,batch_dict[\"y_data\"]).item()\n",
    "        running_acc += (acc_t - running_acc) / (batch_idx + 1)\n",
    "        \n",
    "    train_state[\"train_loss\"].append(running_loss)\n",
    "    train_state[\"train_acc\"].append(running_acc)\n",
    "    \n",
    "    \n",
    "    # iter over val dataset\n",
    "    batch_generator = generate_batches(dataset=val_dataset,\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       device=args.device)\n",
    "    \n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    classifier.eval()\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        with torch.inference_mode():\n",
    "            y_pred = classifier(batch_dict[\"x_data\"].float())\n",
    "            \n",
    "            loss = loss_fn(y_pred,batch_dict[\"y_data\"].float())\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_idx +1)\n",
    "            \n",
    "            # compute teh accuracy\n",
    "            acc_t = acc_fn(y_pred,batch_dict[\"y_data\"].float()).item()\n",
    "            running_acc += (acc_t - running_acc) /(batch_idx + 1)\n",
    "            \n",
    "    train_state[\"val_loss\"].append(running_loss)\n",
    "    train_state[\"val_acc\"].append(running_acc)\n",
    "    \n",
    "    train_state = update_train_state(args=args,model=classifier,train_state=train_state)\n",
    "    scheduler.step(train_state[\"val_loss\"][-1])\n",
    "            \n",
    "    if train_state[\"stop_early\"]:\n",
    "        break \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
