{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from collections import Counter,OrderedDict\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "## other\n",
    "from torchdata import datapipes as dp\n",
    "from torchtext import vocab\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# manipulation\n",
    "import numpy as np\n",
    "\n",
    "# visualization \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# other \n",
    "from tqdm import tqdm       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # data\n",
    "    data_base_path = \"../data/news/\",\n",
    "    data_filename = \"news_with_splits.csv\",\n",
    "    dataset = [\"train\",\"val\",\"test\"],\n",
    "    \n",
    "    # vocab\n",
    "    min_freq = 25,\n",
    "    unk_tkn = \"<UNK>\",\n",
    "    mask_tkn = \"<MASK>\",\n",
    "    begin_seq_tkn = \"<BEGIN>\",\n",
    "    end_seq_tkn = \"<END>\",\n",
    "    \n",
    "    # model\n",
    "    model_base_path = \"../models/news/\",\n",
    "    model_filename = \"model.pth\",\n",
    "    glove_filepath = \"../data/glove/glove.6B.100d.txt\",\n",
    "    hidden_dim = 100,\n",
    "    num_channels = 100,\n",
    "    \n",
    "    # training\n",
    "    num_epochs = 100,\n",
    "    learning_rate = 0.001,\n",
    "    dropout_rate = 0.1,\n",
    "    batch_size = 128,\n",
    "    early_stopping_criteria = 5,\n",
    "    \n",
    "    # runtime\n",
    "    cuda = torch.cuda.is_available(),\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",    \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_fn(args,row):\n",
    "    return args.dataset.index(row[1])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~])\", r\" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "def preprocess_row(row):\n",
    "    return (preprocess_text(row[0]),preprocess_text(row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe_dict(args):\n",
    "    pipe = dp.iter.FileOpener([args.data_base_path+args.data_filename])\n",
    "    pipe = pipe.parse_csv(skip_lines=1)\n",
    "    pipes = pipe.demux(num_instances=len(args.dataset),\n",
    "                      classifier_fn=partial(classification_fn,args),\n",
    "                      buffer_size=1_000_000)\n",
    "    return {k:pipe.map(preprocess_row)\n",
    "            for k,pipe in zip(args.dataset,pipes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = build_pipe_dict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_token_fn(row):\n",
    "    return [row[0]]\n",
    "\n",
    "def title_token_fn(row):\n",
    "    return row[1].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_dict(train_pipe,args=args):\n",
    "    cat_token = train_pipe.map(cat_token_fn)\n",
    "    cat_vocab = vocab.build_vocab_from_iterator(cat_token)\n",
    "    \n",
    "    # title_token = train_pipe.map(title_token_fn)\n",
    "    # title_vocab = vocab.build_vocab_from_iterator(title_token,\n",
    "    #                                               min_freq=args.min_freq,\n",
    "    #                                               specials=[args.unk_tkn,\n",
    "    #                                                         args.mask_tkn,\n",
    "    #                                                         args.begin_seq_tkn,\n",
    "    #                                                         args.end_seq_tkn])\n",
    "    max_length = -1\n",
    "    counter = Counter()\n",
    "    for row in pipe_dict[\"train\"]:\n",
    "        max_length = max(max_length,len(split:=row[1].split(\" \")))\n",
    "        counter.update(split)\n",
    "        \n",
    "    sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: (-x[1], x[0]))    \n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "    title_vocab = vocab.vocab(ordered_dict=ordered_dict,min_freq=args.min_freq,\n",
    "                              specials=[args.unk_tkn,\n",
    "                                        args.mask_tkn,\n",
    "                                        args.begin_seq_tkn,\n",
    "                                        args.end_seq_tkn])\n",
    "    title_vocab.set_default_index(title_vocab[args.unk_tkn])\n",
    "    title_vocab.max_length = max_length\n",
    "    freq = [count for _,count in sorted_by_freq_tuples]\n",
    "    title_vocab.class_weights = 1.0 / torch.tensor(freq,dtype=torch.float32)\n",
    "    \n",
    "             \n",
    "    return {\"cat\":cat_vocab,\n",
    "            \"title\":title_vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:262: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cat': Vocab(), 'title': Vocab()}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = build_vocab_dict(pipe_dict[\"train\"],args)\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"title\"].max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(title,vocab,args=args):\n",
    "    indices = [vocab[args.begin_seq_tkn]]\n",
    "    indices.extend(vocab.lookup_indices(title.split(\" \")))\n",
    "    indices.append(vocab[args.end_seq_tkn])\n",
    "    \n",
    "    vector = np.zeros(shape=vocab.max_length+2,dtype=np.int64)\n",
    "    vector[:(a:=len(indices))] = indices\n",
    "    vector[a:] = vocab[args.mask_tkn]\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "def create_dataset(vocab_dict,args,row):\n",
    "    title_vector = vectorize(row[1],vocab_dict[\"title\"],args)\n",
    "    cat_index = vocab_dict[\"cat\"][row[0]]\n",
    "    return {\"x\":title_vector,\n",
    "            \"y\":cat_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_dict(pipe_dict,vocab_dict,args):\n",
    "    dataset_dict = {}\n",
    "    fn = partial(create_dataset,vocab_dict,args)\n",
    "    for name,pipe in pipe_dict.items():\n",
    "        if name == \"train\":\n",
    "            pipe = pipe.shuffle()\n",
    "        pipe = pipe.map(fn)\n",
    "        pipe = pipe.batch(args.batch_size)\n",
    "        dataset_dict[name] = pipe\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = build_dataset_dict(pipe_dict,vocab_dict,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(args,x):\n",
    "    return {k:v.to(args.device)\n",
    "            for x_ in default_collate(x)\n",
    "            for k ,v in x_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset,shuffle=False,args=args):\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            worker_init_fn=worker_init_fn,\n",
    "                            collate_fn = partial(collate_fn,args),\n",
    "                            drop_last=True)\n",
    "    for batch in dataloader:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(generate_batches(dataset_dict[\"train\"],\n",
    "                               shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[   2,   69,  918,  ...,    1,    1,    1],\n",
       "         [   2,  868,    0,  ...,    1,    1,    1],\n",
       "         [   2,   27, 3257,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,  826, 2231,  ...,    1,    1,    1],\n",
       "         [   2,   27,    8,  ...,    1,    1,    1],\n",
       "         [   2,  343,    0,  ...,    1,    1,    1]]),\n",
       " 'y': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_from_file(glove_filepath):\n",
    "    word_to_idx = {}\n",
    "    embedding_matrix = []\n",
    "    with open(glove_filepath,\"r\") as f:\n",
    "        for idx,line in enumerate(f):\n",
    "            line = line.split(\" \")\n",
    "            word_to_idx[line[0]] = idx\n",
    "            embedding = [float(val) for val in line[1:]]\n",
    "            embedding_matrix.append(embedding)\n",
    "    return word_to_idx,np.stack(embedding_matrix)\n",
    "\n",
    "def create_embedding(glove_filepath,title_vocab):\n",
    "    word_to_idx , pre_trained_embedding = load_glove_from_file(glove_filepath)\n",
    "    embedding_size = pre_trained_embedding.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros(shape=(len(title_vocab),embedding_size))\n",
    "    \n",
    "    for idx,word in enumerate(title_vocab.get_itos()):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[idx,:] = pre_trained_embedding[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_idx = torch.ones(1,embedding_size)\n",
    "            nn.init.xavier_uniform_(embedding_idx)\n",
    "            final_embeddings[idx,:] = embedding_idx\n",
    "    \n",
    "    return final_embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self,embedding_size,num_embedding,\n",
    "                 num_class,num_channels,hidden_dim,\n",
    "                 dropout_rate,pretrained_embedding=None,padding_idx = 0) -> None:\n",
    "        super().__init__()\n",
    "        if pretrained_embedding is not None:\n",
    "            weights = torch.from_numpy(pretrained_embedding).float()\n",
    "            self.embedding = nn.Embedding.from_pretrained(embeddings=weights,\n",
    "                                                          padding_idx=padding_idx)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(num_embeddings=num_embedding,\n",
    "                                          embedding_dim=embedding_size,\n",
    "                                          padding_idx=padding_idx)\n",
    "            \n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_size,\n",
    "                      out_channels=num_channels,kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels,\n",
    "                      out_channels=num_channels,kernel_size=3,stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels,\n",
    "                      out_channels=num_channels,kernel_size=3,stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=num_channels,\n",
    "                      out_channels=num_channels,kernel_size=3),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.fc1 = nn.Linear(in_features=num_channels,\n",
    "                             out_features=hidden_dim)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_dim,\n",
    "                             out_features=num_class)\n",
    "        \n",
    "    def forward(self,input,apply_softmax=False):\n",
    "        # input.shape [batch,max_seq_length]\n",
    "        embed = self.embedding(input)\n",
    "        # shape [batch,max_seq_length,embedding]\n",
    "        #? making the embedding as channels\n",
    "        embed = embed.permute(0,2,1)\n",
    "        # shape [batch,embedding,max_seq_length]\n",
    "        features = self.convnet(embed)\n",
    "        # shape [batch,num_channels,remain_size]\n",
    "        remaining_size = features.size(dim=2)\n",
    "        features = F.avg_pool1d(input=features,kernel_size=remaining_size).squeeze(dim=2)\n",
    "        features = F.dropout(features,p=self.dropout_rate)\n",
    "        # shape [batch,num_channel]\n",
    "        intermediate_vector = F.relu(F.dropout(self.fc1(features),self.dropout_rate))\n",
    "        # shape [batch.hidden_dim]\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        # shape [batch,num_classes]\n",
    "        \n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector,dim=1)\n",
    "            \n",
    "        return prediction_vector            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(generate_batches(dataset_dict[\"train\"])))[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = create_embedding(args.glove_filepath,vocab_dict[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NewsClassifier(embedding_size=embeddings.shape[1],\n",
    "                            num_embedding=embeddings.shape[0],\n",
    "                            num_channels=args.num_channels,\n",
    "                            hidden_dim=args.hidden_dim,\n",
    "                            num_class=len(vocab_dict[\"cat\"]),\n",
    "                            pretrained_embedding=embeddings,\n",
    "                            dropout_rate=args.dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(sample_batch).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args=args):\n",
    "    return {\"stop_early\":False,\n",
    "            \"early_stopping_step\":0,\n",
    "            \"early_stopping_val\":1e8,\n",
    "            \"epoch_index\":0,\n",
    "            \"model_filepath\":args.model_base_path+args.model_filename,\n",
    "            \"train_loss\":[],\n",
    "            \"train_acc\":[],\n",
    "            \"val_loss\":[],\n",
    "            \"val_acc\":[],\n",
    "            \"test_loss\":-1,\n",
    "            \"test_acc\":-1}\n",
    "\n",
    "def update_train_state(train_state,model,args=args):\n",
    "    if train_state[\"epoch_index\"] == 0:\n",
    "        torch.save(model.state_dict(),train_state[\"model_filepath\"])\n",
    "        train_state[\"stop_early\"] = False\n",
    "    \n",
    "    elif train_state[\"epoch_index\"] >= 1:\n",
    "        loss_tm1 , loss_t = train_state[\"val_loss\"][-2:]\n",
    "        if loss_t >= train_state[\"early_stopping_val\"]:\n",
    "            train_state[\"early_stopping_step\"] +=1\n",
    "        else:\n",
    "            torch.save(model.state_dict(),train_state[\"model_filepath\"])\n",
    "            train_state[\"early_stopping_step\"] = 0\n",
    "            \n",
    "        train_state[\"stop_early\"] = train_state[\"early_stopping_step\"] >= args.early_stopping_criteria\n",
    "    \n",
    "    return train_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "pipe_dict = build_pipe_dict(args)\n",
    "vocab_dict = build_vocab_dict(pipe_dict[\"train\"],args=args)\n",
    "dataset_dict = build_dataset_dict(pipe_dict=pipe_dict,vocab_dict=vocab_dict,args=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "embeddings = create_embedding(args.glove_filepath,vocab_dict[\"title\"])\n",
    "classifier = NewsClassifier(embedding_size=embeddings.shape[1],\n",
    "                            num_embedding=len(vocab_dict[\"title\"]),\n",
    "                            num_channels=args.num_channels,\n",
    "                            hidden_dim=args.hidden_dim,\n",
    "                            num_class=len(vocab_dict[\"cat\"]),\n",
    "                            pretrained_embedding=embeddings,\n",
    "                            dropout_rate=args.dropout_rate).to(args.device)\n",
    "# training\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "acc_fn = Accuracy(task=\"multiclass\",num_classes=len(vocab_dict[\"cat\"])).to(args.device)\n",
    "optimizer = optim.Adam(params=classifier.parameters(),\n",
    "                       lr= args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode=\"min\",factor=0.5,patience=1)\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:38<00:00,  6.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(args.num_epochs)):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    \n",
    "    # get the data\n",
    "    batch_generator = generate_batches(dataset=dataset_dict[\"train\"],shuffle=True)\n",
    "    classifier.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        classifier.zero_grad()\n",
    "        logits = classifier(batch_dict[\"x\"])\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_fn(logits,batch_dict[\"y\"])\n",
    "        loss_t = loss.item()\n",
    "        running_loss = (loss_t - running_loss) /(batch_idx+1)\n",
    "        \n",
    "        # acc\n",
    "        acc = acc_fn(logits,batch_dict[\"y\"])\n",
    "        acc_t = acc.item()\n",
    "        running_acc = (acc_t - running_acc) / (batch_idx+1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_state[\"train_loss\"].append(running_loss)\n",
    "    train_state[\"train_acc\"].append(running_acc)\n",
    "    \n",
    "    # iterate over the val \n",
    "    batch_generator = generate_batches(dataset_dict[\"val\"])\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    classifier.eval()\n",
    "    \n",
    "    for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "        with torch.inference_mode():\n",
    "            logits = classifier(batch_dict[\"x\"])\n",
    "            \n",
    "            # loss\n",
    "            loss = loss_fn(logits,batch_dict[\"y\"])\n",
    "            loss_t = loss.item()\n",
    "            running_loss = (loss_t - running_loss) /(batch_idx+1)\n",
    "            \n",
    "            # acc\n",
    "            acc = acc_fn(logits,batch_dict[\"y\"])\n",
    "            acc_t = acc.item()\n",
    "            running_acc = (acc_t - running_acc) / (batch_idx+1)   \n",
    "            \n",
    "    train_state[\"val_loss\"].append(running_loss)         \n",
    "    train_state[\"val_acc\"].append(running_acc)\n",
    "    \n",
    "    scheduler.step(train_state[\"val_loss\"][-1])\n",
    "    \n",
    "    if train_state[\"stop_early\"]:\n",
    "        break          "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(dataset_dict[\"test\"])\n",
    "classifier.eval()\n",
    "running_acc = 0.0 \n",
    "running_loss = 0.0\n",
    "\n",
    "for batch_idx,batch_dict in enumerate(batch_generator):\n",
    "    with torch.inference_mode():\n",
    "        logits = classifier(batch_dict[\"x\"])\n",
    "        # loss\n",
    "        loss = loss_fn(logits,batch_dict[\"y\"])\n",
    "        loss_t = loss.item()\n",
    "        running_loss = (loss_t - running_loss) /(batch_idx+1)\n",
    "        \n",
    "        # acc\n",
    "        acc = acc_fn(logits,batch_dict[\"y\"])\n",
    "        acc_t = acc.item()\n",
    "        running_acc = (acc_t - running_acc) / (batch_idx+1) \n",
    "        \n",
    "train_state[\"test_loss\"]= running_loss\n",
    "train_state[\"test_acc\"] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6771782040596008;\n",
      "Test Accuracy: 0.78125\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(title,classifier,vocab_dict):\n",
    "    title = preprocess_text(title)\n",
    "    vectorized = torch.tensor(vectorize(title,vocab_dict[\"title\"]))\n",
    "    results = classifier(vectorized.unsqueeze(0),apply_softmax=True)\n",
    "    prob,indices = results.max(dim=1)\n",
    "    pred_cat = vocab_dict[\"cat\"].lookup_token(indices.item())\n",
    "    return pred_cat,prob.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sci tech', 0.7965487837791443)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Shape and Dynamic Nature of Carbon-Based Molecules Are Different Than Scientists Thought\"\"\"\n",
    "predict_category(text,classifier,vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "feed = feedparser.parse(\"https://scitechdaily.com/feed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape and Dynamic Nature of Carbon-Based Molecules Are Different Than Scientists Thought\n",
      "('sci tech', 0.7157201170921326)\n",
      "Sleep and Vaccination: The Critical Connection You Need to Know About\n",
      "('sci tech', 0.6424444317817688)\n",
      "Seek & Destroy: Black Widow Spiders Are Being Actively Hunted by Brown Widows\n",
      "('sci tech', 0.454619824886322)\n",
      "Scientists Warn: Food Coloring Nanoparticles May Damage Human Gut\n",
      "('sci tech', 0.7301842570304871)\n",
      "Scientists Discover Previously Unknown Anatomical Structure in the Brain\n",
      "('sci tech', 0.8048786520957947)\n",
      "Nanofiber-Hydrogel Shows Success Treating Severe Complication of Crohn’s Disease\n",
      "('sci tech', 0.5179975628852844)\n",
      "Digital Rectal Exams Are NOT Useful To Early Detect Prostate Cancers\n",
      "('sci tech', 0.9008622765541077)\n",
      "Beware of Fungi in Flour: It Won’t Turn You Into a Zombie, but It Can Make You Sick\n",
      "('sports', 0.8400651216506958)\n",
      "Resisting Treatment: Cancer Cells Shrink or Super-Size To Survive\n",
      "('sci tech', 0.8618530631065369)\n",
      "Compromised “Trust Settings” – An Early Warning of Lurking Depression\n",
      "('sci tech', 0.4839159846305847)\n",
      "Up to 1,000,000 Times Faster: A Switch Made From a Single Molecule\n",
      "('sci tech', 0.829596221446991)\n",
      "This Week @NASA: Artemis Systems Are Ready To Fly Astronauts to the Moon\n",
      "('sci tech', 0.9814673066139221)\n",
      "A New Promising Ultrasound Device Could Treat High Blood Pressure\n",
      "('sci tech', 0.8892253041267395)\n",
      "Webb Spots Globular Cluster Sparkling With Separate Stars in the Milky Way Halo\n",
      "('sports', 0.7400368452072144)\n",
      "Revolutionizing Neuroscience: First-Ever Complete Wiring Map of Insect Brain Neurons\n",
      "('sci tech', 0.7420703768730164)\n",
      "A Dangerous Connection: Depression Linked to Deadly Inflammation in Lung Cancer Patients\n",
      "('world', 0.8879427909851074)\n",
      "New Biosensor Reveals Activity of Elusive Metal That’s Essential for Life\n",
      "('sci tech', 0.8022850751876831)\n",
      "Safe on Earth! NASA’s SpaceX Crew-5 Splash Down Near Florida Coast\n",
      "('sci tech', 0.9099656939506531)\n",
      "Physicists Confirm 50-Year-Old Hypothesis About Selfish Behavior\n",
      "('sports', 0.6432062983512878)\n",
      "Strange Circular Sand Dunes Discovered on Mars by NASA Spacecraft\n",
      "('sci tech', 0.9642544984817505)\n",
      "“Irreversible Degradation” – Existential Threats to the Iconic Nile River Delta Identified\n",
      "('world', 0.5305648446083069)\n",
      "“Unexpected” – Researchers Pinpoint Mysterious Source of Sun’s “Heartbeat-Like” Signals\n",
      "('sci tech', 0.9322613477706909)\n",
      "Oldest Fossils of Mysterious Prehistoric Creature Aren’t What Scientists Thought\n",
      "('sci tech', 0.5810820460319519)\n",
      "Brain Tumor Breakthrough: New Cancer Vulnerability Discovered\n",
      "('sci tech', 0.9189257025718689)\n"
     ]
    }
   ],
   "source": [
    "for entry in feed.entries:\n",
    "    print(entry.title)\n",
    "    print(predict_category(entry.title,classifier,vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC vs RCB, Women's Premier League, Live Score Updates: Match Hangs In Balance As Delhi Capitals Go 4 Down In Chase\n",
      "('sports', 0.9560973644256592)\n",
      "Watch: How New Zealand Helped India Reach World Test Championship Final After Beating Sri Lanka In Last-Ball Thriller\n",
      "('sports', 0.6674612164497375)\n",
      "\"Madness...\": Steve Smith On How Delhi And Ahmedabad Tests Were Different\n",
      "('sports', 0.5860716104507446)\n",
      "How Bad Was Shreyas Iyer's Injury? Rohit Sharma Shares Grave Observation\n",
      "('sports', 0.7295311093330383)\n",
      "\"I Was Called Black Monkey\": Mohammed Siraj Recalls Racism Incident On Australia Tour\n",
      "('sports', 0.3564854860305786)\n",
      "\"Don't Believe What You See On Social Media\": Rohit Sharma Provides Update On Virat Kohli's Health\n",
      "('sci tech', 0.6168894171714783)\n",
      "Watch: Virat Kohli Teases Nitin Menon Over LBW Decision. Umpire's Reaction Goes Viral\n",
      "('sports', 0.4983079731464386)\n",
      "Will IPL Schedule Impact India's WTC Final Chances? Rahul Dravid's Clear Answer\n",
      "('sports', 0.5032055974006653)\n",
      "\"Test Cricket Is Hard-Fought\": Rohit Sharma's Honest Verdict On India's Performance In Border-Gavaskar Trophy\n",
      "('sports', 0.5752102136611938)\n",
      "Ravichandran Ashwin's Hilarious Reaction To Cheteshwar Pujara's Bowling Leaves Everyone In Splits\n",
      "('world', 0.32700198888778687)\n",
      "\"We Can Also Have Security Concerns\": Pakistan Board Chief's Retort To BCCI On Asia Cup Saga\n",
      "('world', 0.5735762119293213)\n",
      "No Babar Azam, Shaheen Afridi As Pakistan Pick Shadab Khan As Captain For Afghanistan T20Is\n",
      "('world', 0.8597566485404968)\n",
      "Harry Brook Beats Ravindra Jadeja To ICC Player Of Month Award, Ashleigh Gardner Too Wins Again\n",
      "('sports', 0.7217954993247986)\n",
      "Fourth Test Ends In Draw, India Seal Series 2-1\n",
      "('sports', 0.8909668326377869)\n",
      "India vs Australia, 4th Test, Day 5 Highlights: India Clinch Series 2-1 As Early Stumps Called\n",
      "('sports', 0.8085549473762512)\n"
     ]
    }
   ],
   "source": [
    "sports = feedparser.parse(\"https://sports.ndtv.com/rss/cricket\")\n",
    "for entry in sports.entries[:15]:\n",
    "    print(entry.title)\n",
    "    print(predict_category(entry.title,classifier,vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
