{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming \n",
    "\n",
    "The process of removing affixes from a word so that we are left with the stem of the word.\n",
    "\n",
    "**Why we need stemming?**\n",
    "1. When we are converting hte textual data into numerical data , we are assuming that all words are independent to each other.\n",
    "2. if we assign the differ vector for all word then we will large dimension of data.\n",
    "3. Most of them will be sparse, them hinder the process of training.\n",
    "4. to avoid these kind of problem we convert word that are similar to common word.\n",
    "5. > run,running,runs ----> run.\n",
    "\n",
    "\n",
    "but this process has problem that it hide the some information present in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = stem.PorterStemmer()\n",
    "lst = stem.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eat', 'eat')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"eating\"),lst.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('live', 'liv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"living\"),lst.stem(\"living\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are working with the part of speech or dependency parser we should avoid stemming , because stemming will modify the token and this can result in a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tradit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"traditional\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming never produce the common word that have meaning to it.\n",
    "\n",
    "\n",
    "There are different type stemming algo like\n",
    "1. Porter (support only english)\n",
    "2. Snowball (modified version of porter support 18 language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem.SnowballStemmer.languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Porter stem only work with string.\n",
    "2. Snowball stem work with string and unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'died', 'agreed', 'owned', \n",
    "           'humbled', 'sized', 'meeting', 'stating', 'siezing', 'itemization', \n",
    "           'traditional', 'reference', 'colonizer', 'plotted', 'having', 'generously']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caress,fli,die,mule,die,agre,own,humbl,size,meet,state,siez,item,tradit,refer,colon,plot,have,gener'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join([pst.stem(word) for word in plurals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caress,fli,die,mule,die,agre,own,humbl,size,meet,state,siez,item,tradit,refer,colon,plot,have,generous'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow = stem.SnowballStemmer(language=\"english\")\n",
    "\",\".join([snow.stem(word) for word in plurals])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "**Over stemming**\n",
    "1. Larger part of word is chopped off than it required which lead to \"two different word will have same stem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('univers', 'univers')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"university\") ,pst.stem(\"universe\")\n",
    "#? this clearly wrong."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under stemming** \n",
    "1. \"two different word that have to reduce into single same word but it reduce into two different word.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data', 'datum')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"data\") ,pst.stem(\"datum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data', 'datum')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem(\"data\"),snow.stem(\"datum\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea56c0b954ae67294c7ca9bf9c057fc748d59d22faedcf3e8a57e0a70ba84c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
